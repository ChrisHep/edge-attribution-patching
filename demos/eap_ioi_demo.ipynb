{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6606875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aoq559/dev/transformer/eap/edge-attribution-patching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44586/3747139492.py:6: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"%load_ext autoreload\")\n",
      "/tmp/ipykernel_44586/3747139492.py:7: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"%autoreload 2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aoq559/dev/transformer/eap/edge-attribution-patching\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "if ipython is not None:\n",
    "    ipython.magic(\"%load_ext autoreload\")\n",
    "    ipython.magic(\"%autoreload 2\")\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import einops\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "from eapp.eap_wrapper import EAP\n",
    "\n",
    "from jaxtyping import Float\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a16eab",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20df2bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt-neo-125M into HookedTransformer\n",
      "Using tokenizer GPT2TokenizerFast(name_or_path='EleutherAI/gpt-neo-125m', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# model = HookedTransformer.from_pretrained(\n",
    "#     'EleutherAI/pythia-12b-deduped-v0',\n",
    "#     center_writing_weights=False,\n",
    "#     center_unembed=False,\n",
    "#     fold_ln=False,\n",
    "#     device=device,\n",
    "#     n_devices=7,\n",
    "#     move_to_device=True,\n",
    "#     dtype='float16'\n",
    "# )\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    'gpt-neo-125M',\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    "    n_devices=5,\n",
    "    move_to_device=True,\n",
    "    dtype='float16'\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125m')\n",
    "print(f\"Using tokenizer {tokenizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4cad0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared-network/shared/2024_ml_master/data/EleutherAI/gpt-neo-125m/intervention_1_shots_max_20_arabic_further_templates.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /shared-network/shared/2024_ml_master/data/EleutherAI/gpt-neo-125m/intervention_1_shots_max_20_arabic_further_templates.pkl\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import yaml\n",
    "import pickle\n",
    "import os\n",
    "class DotDict(dict):\n",
    "    \"\"\" Dot notation access to dictionary attributes \"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "yaml_file_path = \"./conf/config.yaml\"\n",
    "with open(yaml_file_path, \"r\") as f:\n",
    "    args = DotDict(yaml.safe_load(f))\n",
    "\n",
    "file_name = args.data_dir\n",
    "file_name += '/' + str(args.model)\n",
    "file_name += '/intervention_' + str(args.n_shots) + '_shots_max_' + str(args.max_n) + '_' + args.representation\n",
    "file_name += '_further_templates' if args.extended_templates else ''\n",
    "file_name += '.pkl'\n",
    "print(file_name)\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    intervention_list = pickle.load(f)\n",
    "print(\"Loaded data from\", file_name)\n",
    "if args.debug_run:\n",
    "    intervention_list = intervention_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be3f25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2215, 12313,   290, 12091,  1392,   257, 26906,   379,   262,  3650,\n",
       "            11, 12091,  3066,   284,  1577,   340,   284, 12313, 50256, 50256,\n",
       "         50256],\n",
       "        [ 2215, 18501,   290,  8049,  1392,   257, 38987,   379,   262, 11376,\n",
       "            11, 18501,  3066,   284,  1577,   340,   284,  8049, 50256, 50256,\n",
       "         50256],\n",
       "        [ 2215, 12246,   290,  4422,  1392,   257,  4144,   379,   262,  3650,\n",
       "            11,  4422,  3066,   284,  1577,   340,   284, 12246, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11, 17352,   290, 12969,   550,   257,   890,  4578,    11,\n",
       "           290, 12979, 17352,   531,   284, 12969, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11, 11232,   290,  7939,   547,  1762,   379,   262,  1524,\n",
       "            13,  7939,  3066,   284,  1577,   257, 38987,   284, 11232, 50256,\n",
       "         50256],\n",
       "        [ 3260,  9005,   290,  7806,  1816,   284,   262,  4429,    11,  7806,\n",
       "          2921,   257,  3644,   284,  9005, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 2215, 11753,   290, 11328,  1392,   257,  9970,   379,   262, 11376,\n",
       "            11, 11328,  3066,   284,  1577,   340,   284, 11753, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11,  5278,   290,  8049,   550,   257,   890,  4578,    11,\n",
       "           290, 12979,  5278,   531,   284,  8049, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11, 12313,   290,  5613,  1816,   284,   262,  4436,    13,\n",
       "          5613,  2921,   257,  3644,   284, 12313, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11,  7939,   290,  3977,   550,   257,   890,  4578,    11,\n",
       "           290, 12979,  3977,   531,   284,  7939, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11, 10443,   290,  6047,   550,   257,  1256,   286,  1257,\n",
       "           379,   262,  2156,    13,  6047,  2921,   257,  4144,   284, 10443,\n",
       "         50256],\n",
       "        [ 6423,    11, 14757,   290, 11264,   550,   257,   890,  4578,    11,\n",
       "           290, 12979, 14757,   531,   284, 11264, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11,  3362,   290, 16753,   550,   257,  1256,   286,  1257,\n",
       "           379,   262,  7072,    13, 16753,  2921,   257,  4144,   284,  3362,\n",
       "         50256],\n",
       "        [ 3260, 10888,   290,  9077,  1816,   284,   262,  4429,    11, 10888,\n",
       "          2921,   257,  5858,   284,  9077, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 2215,  3977,   290,  5199,  1392,   257,  9970,   379,   262,  2156,\n",
       "            11,  3977,  3066,   284,  1577,   340,   284,  5199, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11,  3271,   290, 14316,  1816,   284,   262,  1524,    13,\n",
       "          3271,  2921,   257,  9669,   284, 14316, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11,  3619,   290, 16753,   547,  3612,   546,  1016,   284,\n",
       "           262,  2607,    13,  3619,  2227,   284,  1577,   257, 26906,   284,\n",
       "         16753],\n",
       "        [ 2215, 11336,   290,  3362,  1392,   257,  4144,   379,   262,  3650,\n",
       "            11, 11336,  3066,   284,  1577,   340,   284,  3362, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11, 14886,   290, 11563,   547,  1762,   379,   262,  7072,\n",
       "            13, 11563,  3066,   284,  1577,   257,  9669,   284, 14886, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11, 16693,   290, 10948,   547,  3612,   546,  1016,   284,\n",
       "           262,  1524,    13, 16693,  2227,   284,  1577,   257,  4144,   284,\n",
       "         10948],\n",
       "        [ 6423,    11,  5658,   290, 12806,   550,   257,  1256,   286,  1257,\n",
       "           379,   262,  2607,    13, 12806,  2921,   257,  5858,   284,  5658,\n",
       "         50256],\n",
       "        [ 6423,    11,  5593,   290,  5436,  1816,   284,   262,  2607,    13,\n",
       "          5436,  2921,   257, 26906,   284,  5593, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11,  4422,   290, 18501,   550,   257,   890,  4578,    11,\n",
       "           290, 12979, 18501,   531,   284,  4422, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11, 18501,   290,  9953,   547,  1762,   379,   262,  4436,\n",
       "            13, 18501,  3066,   284,  1577,   257,  5858,   284,  9953, 50256,\n",
       "         50256],\n",
       "        [ 6423,    11, 12382,   290,  9005,   547,  1762,   379,   262,  3650,\n",
       "            13, 12382,  3066,   284,  1577,   257, 26906,   284,  9005, 50256,\n",
       "         50256]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset.toks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292dfbf6",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "601a7d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      Sentences from IOI vs ABC distribution                                       </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> IOI prompt                              </span>┃<span style=\"font-weight: bold\"> IOI subj </span>┃<span style=\"font-weight: bold\"> IOI indirect obj </span>┃<span style=\"font-weight: bold\"> ABC prompt                              </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> got a snack at   │ Jane     │ Victoria         │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> got a snack at   │\n",
       "│ the store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> decided to give it to   │          │                  │ the store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> decided to give it to   │\n",
       "│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span>                                │          │                  │ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span>                                │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span> got a necklace   │ Sullivan │ Rose             │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span> got a necklace   │\n",
       "│ at the garden, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> decided to give │          │                  │ at the garden, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> decided to give │\n",
       "│ it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span>                              │          │                  │ it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span>                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> got a drink at the   │ Alex     │ Alan             │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> got a drink at the   │\n",
       "│ store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> decided to give it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span>  │          │                  │ store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> decided to give it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span>  │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span> had a long    │ Jessica  │ Crystal          │ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span> had a long    │\n",
       "│ argument, and afterwards <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> said   │          │                  │ argument, and afterwards <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> said   │\n",
       "│ to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span>                              │          │                  │ to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span>                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> were working   │ Kevin    │ Jonathan         │ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> were working   │\n",
       "│ at the school. <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> decided to give a  │          │                  │ at the school. <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> decided to give a  │\n",
       "│ necklace to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span>                    │          │                  │ necklace to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span>                    │\n",
       "│                                         │          │                  │                                         │\n",
       "└─────────────────────────────────────────┴──────────┴──────────────────┴─────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                      Sentences from IOI vs ABC distribution                                       \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mIOI prompt                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIOI subj\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIOI indirect obj\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mABC prompt                             \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ When \u001b[1;4;38;5;208mVictoria\u001b[0m and \u001b[1;4;38;5;208mJane\u001b[0m got a snack at   │ Jane     │ Victoria         │ When \u001b[1;4;38;5;208mVictoria\u001b[0m and \u001b[1;4;38;5;208mJane\u001b[0m got a snack at   │\n",
       "│ the store, \u001b[1;4;38;5;208mJane\u001b[0m decided to give it to   │          │                  │ the store, \u001b[1;4;38;5;208mJane\u001b[0m decided to give it to   │\n",
       "│ \u001b[1;4;38;5;208mVictoria\u001b[0m                                │          │                  │ \u001b[1;4;38;5;208mVictoria\u001b[0m                                │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When \u001b[1;4;38;5;208mSullivan\u001b[0m and \u001b[1;4;38;5;208mRose\u001b[0m got a necklace   │ Sullivan │ Rose             │ When \u001b[1;4;38;5;208mSullivan\u001b[0m and \u001b[1;4;38;5;208mRose\u001b[0m got a necklace   │\n",
       "│ at the garden, \u001b[1;4;38;5;208mSullivan\u001b[0m decided to give │          │                  │ at the garden, \u001b[1;4;38;5;208mSullivan\u001b[0m decided to give │\n",
       "│ it to \u001b[1;4;38;5;208mRose\u001b[0m                              │          │                  │ it to \u001b[1;4;38;5;208mRose\u001b[0m                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When \u001b[1;4;38;5;208mAlan\u001b[0m and \u001b[1;4;38;5;208mAlex\u001b[0m got a drink at the   │ Alex     │ Alan             │ When \u001b[1;4;38;5;208mAlan\u001b[0m and \u001b[1;4;38;5;208mAlex\u001b[0m got a drink at the   │\n",
       "│ store, \u001b[1;4;38;5;208mAlex\u001b[0m decided to give it to \u001b[1;4;38;5;208mAlan\u001b[0m  │          │                  │ store, \u001b[1;4;38;5;208mAlex\u001b[0m decided to give it to \u001b[1;4;38;5;208mAlan\u001b[0m  │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, \u001b[1;4;38;5;208mJessica\u001b[0m and \u001b[1;4;38;5;208mCrystal\u001b[0m had a long    │ Jessica  │ Crystal          │ Then, \u001b[1;4;38;5;208mJessica\u001b[0m and \u001b[1;4;38;5;208mCrystal\u001b[0m had a long    │\n",
       "│ argument, and afterwards \u001b[1;4;38;5;208mJessica\u001b[0m said   │          │                  │ argument, and afterwards \u001b[1;4;38;5;208mJessica\u001b[0m said   │\n",
       "│ to \u001b[1;4;38;5;208mCrystal\u001b[0m                              │          │                  │ to \u001b[1;4;38;5;208mCrystal\u001b[0m                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, \u001b[1;4;38;5;208mJonathan\u001b[0m and \u001b[1;4;38;5;208mKevin\u001b[0m were working   │ Kevin    │ Jonathan         │ Then, \u001b[1;4;38;5;208mJonathan\u001b[0m and \u001b[1;4;38;5;208mKevin\u001b[0m were working   │\n",
       "│ at the school. \u001b[1;4;38;5;208mKevin\u001b[0m decided to give a  │          │                  │ at the school. \u001b[1;4;38;5;208mKevin\u001b[0m decided to give a  │\n",
       "│ necklace to \u001b[1;4;38;5;208mJonathan\u001b[0m                    │          │                  │ necklace to \u001b[1;4;38;5;208mJonathan\u001b[0m                    │\n",
       "│                                         │          │                  │                                         │\n",
       "└─────────────────────────────────────────┴──────────┴──────────────────┴─────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ioi_dataset import IOIDataset, format_prompt, make_table\n",
    "N = 25\n",
    "clean_dataset = IOIDataset(\n",
    "    prompt_type='mixed',\n",
    "    N=N,\n",
    "    tokenizer=model.tokenizer,\n",
    "    prepend_bos=False,\n",
    "    seed=1,\n",
    "    device=device\n",
    ")\n",
    "corr_dataset = clean_dataset.gen_flipped_prompts('ABC->XYZ, BAB->XYZ')\n",
    "\n",
    "make_table(\n",
    "  colnames = [\"IOI prompt\", \"IOI subj\", \"IOI indirect obj\", \"ABC prompt\"],\n",
    "  cols = [\n",
    "    map(format_prompt, clean_dataset.sentences),\n",
    "    model.to_string(clean_dataset.s_tokenIDs).split(),\n",
    "    model.to_string(clean_dataset.io_tokenIDs).split(),\n",
    "    map(format_prompt, clean_dataset.sentences),\n",
    "  ],\n",
    "  title = \"Sentences from IOI vs ABC distribution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657f126",
   "metadata": {},
   "source": [
    "# Metric Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e71a358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1315]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'op3_pos': 18,\n",
       " 'operator_word': None,\n",
       " 'operands_alt': '2 7 6',\n",
       " 'operands_base': '2 7 6',\n",
       " 'operator_pos': None,\n",
       " 'op2_pos': 16,\n",
       " 'op1_pos': 14,\n",
       " 'res_alt_tok': [1315],\n",
       " 'res_base_tok': [1315],\n",
       " 'res_string': None,\n",
       " 'res_base_string': '15',\n",
       " 'res_alt_string': '15',\n",
       " 'device': 'cpu',\n",
       " 'multitoken': False,\n",
       " 'is_llama': False,\n",
       " 'is_opt': False,\n",
       " 'is_bloom': False,\n",
       " 'is_mistral': False,\n",
       " 'is_persimmon': False,\n",
       " 'representation': 'arabic',\n",
       " 'extended_templates': True,\n",
       " 'template_id': '-',\n",
       " 'n_vars': 2,\n",
       " 'base_string': 'The result of 2 + 7 + 6 =',\n",
       " 'alt_string': 'The result of 2 + 7 + 6 =',\n",
       " 'few_shots': 'The result of 7 + 5 + 3 = 15. ',\n",
       " 'few_shots_t2': ' ',\n",
       " 'equation': '({x}+{y} + {z})',\n",
       " 'enc': GPT2Tokenizer(name_or_path='EleutherAI/gpt-neo-125m', vocab_size=50257, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " },\n",
       " 'len_few_shots': 12,\n",
       " 'len_few_shots_t2': 1,\n",
       " 'base_string_tok_list': [464,\n",
       "  1255,\n",
       "  286,\n",
       "  767,\n",
       "  1343,\n",
       "  642,\n",
       "  1343,\n",
       "  513,\n",
       "  796,\n",
       "  1315,\n",
       "  13,\n",
       "  383,\n",
       "  1255,\n",
       "  286,\n",
       "  362,\n",
       "  1343,\n",
       "  767,\n",
       "  1343,\n",
       "  718,\n",
       "  796],\n",
       " 'alt_string_tok_list': [220,\n",
       "  220,\n",
       "  220,\n",
       "  220,\n",
       "  220,\n",
       "  220,\n",
       "  220,\n",
       "  220,\n",
       "  220,\n",
       "  220,\n",
       "  50256,\n",
       "  383,\n",
       "  1255,\n",
       "  286,\n",
       "  362,\n",
       "  1343,\n",
       "  767,\n",
       "  1343,\n",
       "  718,\n",
       "  796],\n",
       " 'base_string_tok': tensor([[ 464, 1255,  286,  767, 1343,  642, 1343,  513,  796, 1315,   13,  383,\n",
       "          1255,  286,  362, 1343,  767, 1343,  718,  796]]),\n",
       " 'alt_string_tok': tensor([[  220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          50256,   383,  1255,   286,   362,  1343,   767,  1343,   718,   796]]),\n",
       " 'pred_alt_string': ' 8',\n",
       " 'pred_res_alt_tok': [807]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervention = intervention_list[0]\n",
    "print(intervention.res_base_tok)\n",
    "intervention.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10d0ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -7.465  -6.3    -8.26  ... -13.19   -9.43   -6.61 ]\n",
      "  [ -7.74  -10.9   -15.34  ... -20.4   -18.86  -14.484]\n",
      "  [-12.34  -10.46  -13.24  ... -14.28  -12.445 -10.54 ]\n",
      "  ...\n",
      "  [-13.74  -12.58  -14.51  ... -22.11  -15.08  -10.7  ]\n",
      "  [-11.086 -12.234 -14.95  ... -23.89  -17.08  -11.43 ]\n",
      "  [-11.68  -11.29  -13.55  ... -18.84  -12.17   -7.54 ]]]\n",
      "1315\n",
      "[-0.77]\n",
      "[0.03464]\n"
     ]
    }
   ],
   "source": [
    "intervention = intervention_list[0]\n",
    "with torch.no_grad():\n",
    "    clean_logits = model(intervention.base_string_tok).cpu().numpy()\n",
    "    print(clean_logits)\n",
    "    corrupt_logits = model(intervention.alt_string_tok).cpu().numpy()\n",
    "    clean_logits_argmax = np.argmax(clean_logits, axis=2)[0, -1]\n",
    "    print(clean_logits_argmax)\n",
    "    clean_logit = clean_logits[:, -1, intervention.res_base_tok[0]]\n",
    "    corrupt_logit = corrupt_logits[:, -1, intervention.pred_res_alt_tok[0]]\n",
    "    logit_diff = corrupt_logit - clean_logit\n",
    "    print(clean_logit)\n",
    "    print(corrupt_logit)\n",
    "\n",
    "    \n",
    "    # clean_logit_argmax = torch.argmax(clean_logits, dim=2)\n",
    "    # corrupt_logit_argmax = torch.argmax(corrupt_logits, dim=2)\n",
    "    # print(clean_logit_argmax)\n",
    "    # next_word_index = clean_logit_argmax[0][-1]\n",
    "    # next_word = model.tokenizer.convert_ids_to_tokens(next_word_index.item())\n",
    "    # print(next_word)\n",
    "    \n",
    "    # clean_prediction = torch.argmax(clean_logits, dim=2)\n",
    "    # print(clean_prediction)\n",
    "    # next_word_index = clean_prediction[0][-1]\n",
    "    # next_word = tokenizer.convert_ids_to_tokens(next_word_index.item())\n",
    "    # print(next_word_index)\n",
    "    # print(next_word)\n",
    "    # print(torch.argmax(clean_logits[:, -1, :]))\n",
    "    # print(corrupt_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "738b27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1315, 1467]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the stacked tensors\n",
    "stacked = []\n",
    "# Iterate over each intervention in intervention_list\n",
    "for intervention in intervention_list:\n",
    "    # Vertically stack the 2-D tensor and append it to the list\n",
    "    stacked.append(intervention.res_base_tok[0])\n",
    "print(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4878b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the stacked tensors\n",
    "stacked_tensors = []\n",
    "# Iterate over each intervention in intervention_list\n",
    "for intervention in intervention_list:\n",
    "    # Vertically stack the 2-D tensor and append it to the list\n",
    "    stacked_tensors.append(intervention.base_string_tok.to(device))\n",
    "# Convert the list of stacked tensors into a single tensor\n",
    "dataset = torch.vstack(stacked_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a02f4793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[807, 513]\n"
     ]
    }
   ],
   "source": [
    "import intervention_dataset\n",
    "intervention_data = intervention_dataset.InterventionDataset(intervention_list, device, model.tokenizer)\n",
    "intervention_data.create_intervention_dataset()\n",
    "print(intervention_data.pred_res_alt_toks[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83150931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -7.4648,  -6.3008,  -8.2578,  ..., -13.1875,  -9.4297,  -6.6094],\n",
      "         [ -7.7383, -10.8984, -15.3438,  ..., -20.4062, -18.8594, -14.4844],\n",
      "         [-12.3438, -10.4609, -13.2422,  ..., -14.2812, -12.4453, -10.5391],\n",
      "         ...,\n",
      "         [-13.7422, -12.5781, -14.5078,  ..., -22.1094, -15.0781, -10.7031],\n",
      "         [-11.0859, -12.2344, -14.9531,  ..., -23.8906, -17.0781, -11.4297],\n",
      "         [-11.6797, -11.2891, -13.5469,  ..., -18.8438, -12.1719,  -7.5391]],\n",
      "\n",
      "        [[ -7.4648,  -6.3008,  -8.2578,  ..., -13.1875,  -9.4297,  -6.6094],\n",
      "         [ -7.7383, -10.8984, -15.3438,  ..., -20.4062, -18.8594, -14.4844],\n",
      "         [-12.3438, -10.4609, -13.2422,  ..., -14.2812, -12.4453, -10.5391],\n",
      "         ...,\n",
      "         [-13.4297, -12.4141, -15.0938,  ..., -22.2812, -15.5703, -10.2109],\n",
      "         [-10.4844, -12.4688, -15.3672,  ..., -23.6875, -17.6875, -11.6172],\n",
      "         [-11.4219, -10.7031, -14.1172,  ..., -18.4844, -12.7969,  -8.2266]]],\n",
      "       device='cuda:5', dtype=torch.float16)\n",
      "2\n",
      "tensor([-7.5391, -8.2266], device='cuda:5', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "with t.no_grad():\n",
    "    clean_logits = model(dataset)\n",
    "print(clean_logits)\n",
    "batch_size = clean_logits.size(0)\n",
    "print(batch_size)\n",
    "clean_logits = clean_logits[range(batch_size), -1, [-1, -1]]\n",
    "print(clean_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ae31a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.699\n",
      "1.229\n"
     ]
    }
   ],
   "source": [
    "def ave_logit_difference(\n",
    "    logits: Float[Tensor, 'batch seq d_vocab'],\n",
    "    intervention_dataset,\n",
    "    per_prompt: bool = False\n",
    "):\n",
    "    batch_size = logits.size(0)\n",
    "    clean_logits = logits[range(batch_size), -1, intervention_dataset.res_base_toks[:batch_size]].cpu().numpy()\n",
    "    corrupt_logits = logits[range(batch_size), -1, intervention_dataset.pred_res_alt_toks[:batch_size]].cpu().numpy()\n",
    "    logit_diff = corrupt_logits - clean_logits\n",
    "    return logit_diff if per_prompt else logit_diff.mean()\n",
    "    \n",
    "    \n",
    "with t.no_grad():\n",
    "    clean_logits = model(intervention_data.base_string_toks)\n",
    "    corrupt_logits = model(intervention_data.alt_string_toks)\n",
    "    clean_logit_diff = ave_logit_difference(clean_logits, intervention_data, per_prompt=False)\n",
    "    corrupt_logit_diff = ave_logit_difference(corrupt_logits, intervention_data, per_prompt=False)\n",
    "print(clean_logit_diff)\n",
    "print(corrupt_logit_diff)\n",
    "\n",
    "def metric(\n",
    "    logits: Float[Tensor, \"batch seq_len d_vocab\"],\n",
    "    corrupted_logit_diff: float = corrupt_logit_diff,\n",
    "    clean_logit_diff: float = clean_logit_diff,\n",
    "    intervention_dataset: intervention_dataset = clean_dataset\n",
    " ):\n",
    "    patched_logit_diff = ave_logit_difference(logits, intervention_dataset)\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (clean_logit_diff - corrupted_logit_diff)\n",
    "\n",
    "\n",
    "# Get clean and corrupt logit differences\n",
    "with t.no_grad():\n",
    "    clean_metric = metric(clean_logits, corrupt_logit_diff, clean_logit_diff, clean_dataset)\n",
    "    corrupt_metric = metric(corrupt_logits, corrupt_logit_diff, clean_logit_diff, corr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "955340ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 464, 1255,  286,  767, 1343,  642, 1343,  513,  796, 1315,   13,  383,\n",
       "         1255,  286,  362, 1343,  767, 1343,  718,  796],\n",
       "        [ 464, 1255,  286,  642, 1343,  642, 1343,  718,  796, 1467,   13,  383,\n",
       "         1255,  286,  513, 1343,  604, 1343,  860,  796]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f34e027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_logits[:, -1, :].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0a1752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15\n",
      "[1315]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The result of 7 + 5 + 3 = 15. The result of 2 + 7 + 6 ='"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained('EleutherAI/pythia-12b-deduped-v0')\n",
    "print(tokenizer.decode(intervention.res_base_tok))\n",
    "print(intervention.res_base_tok)\n",
    "tokenizer.decode(intervention.base_string_tok[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b9d4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean direction: 2.805162191390991, Corrupt direction: 1.4692586660385132\n",
      "Clean metric: 1.0, Corrupt metric: 0.0\n"
     ]
    }
   ],
   "source": [
    "def ave_logit_diff(\n",
    "    logits: Float[Tensor, 'batch seq d_vocab'],\n",
    "    ioi_dataset: IOIDataset,\n",
    "    per_prompt: bool = False\n",
    "):\n",
    "    '''\n",
    "        Return average logit difference between correct and incorrect answers\n",
    "    '''\n",
    "    # Get logits for indirect objects\n",
    "    batch_size = logits.size(0)\n",
    "    # logits[batch_size, last_position, ID of IO]\n",
    "    io_logits = logits[range(batch_size), ioi_dataset.word_idx['end'][:batch_size], ioi_dataset.io_tokenIDs[:batch_size]]\n",
    "    s_logits = logits[range(batch_size), ioi_dataset.word_idx['end'][:batch_size], ioi_dataset.s_tokenIDs[:batch_size]]\n",
    "    # Get logits for subject\n",
    "    logit_diff = io_logits - s_logits\n",
    "    return logit_diff if per_prompt else logit_diff.mean()\n",
    "\n",
    "with t.no_grad():\n",
    "    clean_logits = model(clean_dataset.toks)\n",
    "    corrupt_logits = model(corr_dataset.toks)\n",
    "    clean_logit_diff = ave_logit_diff(clean_logits, clean_dataset).item() # logit difference for clean run between correct and incorrect answer\n",
    "    corrupt_logit_diff = ave_logit_diff(corrupt_logits, corr_dataset).item() # logit difference for corrupt run between correct and incorrect answer\n",
    "\n",
    "def ioi_metric(\n",
    "    logits: Float[Tensor, \"batch seq_len d_vocab\"],\n",
    "    corrupted_logit_diff: float = corrupt_logit_diff,\n",
    "    clean_logit_diff: float = clean_logit_diff,\n",
    "    ioi_dataset: IOIDataset = clean_dataset\n",
    " ):\n",
    "    patched_logit_diff = ave_logit_diff(logits, ioi_dataset)\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (clean_logit_diff - corrupted_logit_diff)\n",
    "\n",
    "def negative_ioi_metric(logits: Float[Tensor, \"batch seq_len d_vocab\"]):\n",
    "    return -ioi_metric(logits)\n",
    "    \n",
    "# Get clean and corrupt logit differences\n",
    "with t.no_grad():\n",
    "    clean_metric = ioi_metric(clean_logits, corrupt_logit_diff, clean_logit_diff, clean_dataset)\n",
    "    corrupt_metric = ioi_metric(corrupt_logits, corrupt_logit_diff, clean_logit_diff, corr_dataset)\n",
    "\n",
    "print(f'Clean direction: {clean_logit_diff}, Corrupt direction: {corrupt_logit_diff}')\n",
    "print(f'Clean metric: {clean_metric}, Corrupt metric: {corrupt_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81ab6e",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activations requires 0.0004 GB of memory per token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head.9.9 -> [-0.029] -> head.11.10.q\n",
      "head.10.7 -> [0.029] -> head.11.10.q\n",
      "head.5.5 -> [0.021] -> head.8.6.v\n",
      "head.9.9 -> [-0.019] -> head.10.7.q\n",
      "head.5.5 -> [-0.019] -> mlp.5\n",
      "mlp.0 -> [0.018] -> head.6.9.q\n",
      "mlp.0 -> [-0.015] -> mlp.4\n",
      "head.5.5 -> [-0.015] -> head.6.9.q\n",
      "mlp.0 -> [-0.014] -> head.11.10.k\n",
      "head.3.0 -> [-0.014] -> mlp.5\n"
     ]
    }
   ],
   "source": [
    "model.reset_hooks()\n",
    "\n",
    "graph = EAP(\n",
    "    model,\n",
    "    clean_dataset.toks,\n",
    "    corr_dataset.toks,\n",
    "    ioi_metric,\n",
    "    upstream_nodes=[\"mlp\", \"head\"],\n",
    "    downstream_nodes=[\"mlp\", \"head\"],\n",
    "    batch_size=25\n",
    ")\n",
    "\n",
    "top_edges = graph.top_edges(n=10, abs_scores=True)\n",
    "for from_edge, to_edge, score in top_edges:\n",
    "    print(f'{from_edge} -> [{round(score, 3)}] -> {to_edge}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5bb8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('head.9.9', 'head.11.10.q', -0.0291709266602993),\n",
       " ('head.10.7', 'head.11.10.q', 0.02903885766863823),\n",
       " ('head.5.5', 'head.8.6.v', 0.020961817353963852),\n",
       " ('head.9.9', 'head.10.7.q', -0.01940404810011387),\n",
       " ('head.5.5', 'mlp.5', -0.018816370517015457),\n",
       " ('mlp.0', 'head.6.9.q', 0.01845172606408596),\n",
       " ('mlp.0', 'mlp.4', -0.0152858542278409),\n",
       " ('head.5.5', 'head.6.9.q', -0.014597196131944656),\n",
       " ('mlp.0', 'head.11.10.k', -0.013949546962976456),\n",
       " ('head.3.0', 'mlp.5', -0.013543691486120224)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
