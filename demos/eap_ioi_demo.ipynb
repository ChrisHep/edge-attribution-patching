{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6606875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aoq559/dev/transformer/eap/edge-attribution-patching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49049/2219647472.py:6: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"%load_ext autoreload\")\n",
      "/tmp/ipykernel_49049/2219647472.py:7: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"%autoreload 2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aoq559/dev/transformer/eap/edge-attribution-patching\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "if ipython is not None:\n",
    "    ipython.magic(\"%load_ext autoreload\")\n",
    "    ipython.magic(\"%autoreload 2\")\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import einops\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from eapp.eap_wrapper import EAP\n",
    "\n",
    "from jaxtyping import Float\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a16eab",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20df2bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e3159e9fe6481db0f7ece142fae955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aoq559/miniconda3/envs/eap/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-12b-deduped-v0 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    'EleutherAI/pythia-12b-deduped-v0',\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    "    n_devices=7,\n",
    "    move_to_device=True,\n",
    "    dtype='float16'\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4cad0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared-network/shared/2024_ml_master/data/EleutherAI/pythia-12b-deduped-v0/intervention_1_shots_max_20_words_further_templates.pkl\n",
      "Loaded data from /shared-network/shared/2024_ml_master/data/EleutherAI/pythia-12b-deduped-v0/intervention_1_shots_max_20_words_further_templates.pkl\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import yaml\n",
    "import pickle\n",
    "import os\n",
    "class DotDict(dict):\n",
    "    \"\"\" Dot notation access to dictionary attributes \"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "yaml_file_path = \"./conf/config.yaml\"\n",
    "with open(yaml_file_path, \"r\") as f:\n",
    "    args = DotDict(yaml.safe_load(f))\n",
    "\n",
    "file_name = args.data_dir\n",
    "file_name += '/' + str(args.model)\n",
    "file_name += '/intervention_' + str(args.n_shots) + '_shots_max_' + str(args.max_n) + '_' + args.representation\n",
    "file_name += '_further_templates' if args.extended_templates else ''\n",
    "file_name += '.pkl'\n",
    "print(file_name)\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    intervention_list = pickle.load(f)\n",
    "print(\"Loaded data from\", file_name)\n",
    "if args.debug_run:\n",
    "    intervention_list = intervention_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be3f25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 1,\n",
       " 'has_been_flipped': False,\n",
       " 'prompt_type': 'mixed',\n",
       " 'templates': ['When [A] and [B] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]',\n",
       "  'Then, [A] and [B] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]',\n",
       "  'Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]',\n",
       "  'After [A] and [B] went to the [PLACE], [B] gave a [OBJECT] to [A]',\n",
       "  'When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]',\n",
       "  'After [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]',\n",
       "  'Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]',\n",
       "  'Then, [A] and [B] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]',\n",
       "  'Then, [A] and [B] went to the [PLACE]. [B] gave a [OBJECT] to [A]',\n",
       "  'Then, [A] and [B] had a long argument, and afterwards [B] said to [A]',\n",
       "  'Then, [B] and [A] had a long argument, and afterwards [B] said to [A]',\n",
       "  'Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]',\n",
       "  'Then, [A] and [B] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]',\n",
       "  'Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]'],\n",
       " 'tokenizer': GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       " },\n",
       " 'prefixes': None,\n",
       " 'ioi_prompts': [{'[PLACE]': 'store',\n",
       "   '[OBJECT]': 'snack',\n",
       "   'text': 'When Victoria and Jane got a snack at the store, Jane decided to give it to Victoria',\n",
       "   'IO': 'Victoria',\n",
       "   'S': 'Jane',\n",
       "   'TEMPLATE_IDX': 0},\n",
       "  {'[PLACE]': 'garden',\n",
       "   '[OBJECT]': 'necklace',\n",
       "   'text': 'When Sullivan and Rose got a necklace at the garden, Sullivan decided to give it to Rose',\n",
       "   'IO': 'Rose',\n",
       "   'S': 'Sullivan',\n",
       "   'TEMPLATE_IDX': 4},\n",
       "  {'[PLACE]': 'store',\n",
       "   '[OBJECT]': 'drink',\n",
       "   'text': 'When Alan and Alex got a drink at the store, Alex decided to give it to Alan',\n",
       "   'IO': 'Alan',\n",
       "   'S': 'Alex',\n",
       "   'TEMPLATE_IDX': 0},\n",
       "  {'[PLACE]': 'store',\n",
       "   '[OBJECT]': 'basketball',\n",
       "   'text': 'Then, Jessica and Crystal had a long argument, and afterwards Jessica said to Crystal',\n",
       "   'IO': 'Crystal',\n",
       "   'S': 'Jessica',\n",
       "   'TEMPLATE_IDX': 10},\n",
       "  {'[PLACE]': 'school',\n",
       "   '[OBJECT]': 'necklace',\n",
       "   'text': 'Then, Jonathan and Kevin were working at the school. Kevin decided to give a necklace to Jonathan',\n",
       "   'IO': 'Jonathan',\n",
       "   'S': 'Kevin',\n",
       "   'TEMPLATE_IDX': 12},\n",
       "  {'[PLACE]': 'station',\n",
       "   '[OBJECT]': 'computer',\n",
       "   'text': 'After Prince and Daniel went to the station, Daniel gave a computer to Prince',\n",
       "   'IO': 'Prince',\n",
       "   'S': 'Daniel',\n",
       "   'TEMPLATE_IDX': 3},\n",
       "  {'[PLACE]': 'garden',\n",
       "   '[OBJECT]': 'bone',\n",
       "   'text': 'When Jeremy and Warren got a bone at the garden, Warren decided to give it to Jeremy',\n",
       "   'IO': 'Jeremy',\n",
       "   'S': 'Warren',\n",
       "   'TEMPLATE_IDX': 0},\n",
       "  {'[PLACE]': 'office',\n",
       "   '[OBJECT]': 'drink',\n",
       "   'text': 'Then, Frank and Rose had a long argument, and afterwards Frank said to Rose',\n",
       "   'IO': 'Rose',\n",
       "   'S': 'Frank',\n",
       "   'TEMPLATE_IDX': 10},\n",
       "  {'[PLACE]': 'hospital',\n",
       "   '[OBJECT]': 'computer',\n",
       "   'text': 'Then, Victoria and Peter went to the hospital. Peter gave a computer to Victoria',\n",
       "   'IO': 'Victoria',\n",
       "   'S': 'Peter',\n",
       "   'TEMPLATE_IDX': 8},\n",
       "  {'[PLACE]': 'house',\n",
       "   '[OBJECT]': 'ring',\n",
       "   'text': 'Then, Kevin and William had a long argument, and afterwards William said to Kevin',\n",
       "   'IO': 'Kevin',\n",
       "   'S': 'William',\n",
       "   'TEMPLATE_IDX': 9},\n",
       "  {'[PLACE]': 'house',\n",
       "   '[OBJECT]': 'drink',\n",
       "   'text': 'Then, Edward and Ryan had a lot of fun at the house. Ryan gave a drink to Edward',\n",
       "   'IO': 'Edward',\n",
       "   'S': 'Ryan',\n",
       "   'TEMPLATE_IDX': 7},\n",
       "  {'[PLACE]': 'office',\n",
       "   '[OBJECT]': 'kiss',\n",
       "   'text': 'Then, Jake and Clark had a long argument, and afterwards Jake said to Clark',\n",
       "   'IO': 'Clark',\n",
       "   'S': 'Jake',\n",
       "   'TEMPLATE_IDX': 10},\n",
       "  {'[PLACE]': 'restaurant',\n",
       "   '[OBJECT]': 'drink',\n",
       "   'text': 'Then, Paul and Laura had a lot of fun at the restaurant. Laura gave a drink to Paul',\n",
       "   'IO': 'Paul',\n",
       "   'S': 'Laura',\n",
       "   'TEMPLATE_IDX': 7},\n",
       "  {'[PLACE]': 'station',\n",
       "   '[OBJECT]': 'ring',\n",
       "   'text': 'After Ruby and Kelly went to the station, Ruby gave a ring to Kelly',\n",
       "   'IO': 'Kelly',\n",
       "   'S': 'Ruby',\n",
       "   'TEMPLATE_IDX': 5},\n",
       "  {'[PLACE]': 'house',\n",
       "   '[OBJECT]': 'bone',\n",
       "   'text': 'When William and Robert got a bone at the house, William decided to give it to Robert',\n",
       "   'IO': 'Robert',\n",
       "   'S': 'William',\n",
       "   'TEMPLATE_IDX': 4},\n",
       "  {'[PLACE]': 'school',\n",
       "   '[OBJECT]': 'basketball',\n",
       "   'text': 'Then, David and Kyle went to the school. David gave a basketball to Kyle',\n",
       "   'IO': 'Kyle',\n",
       "   'S': 'David',\n",
       "   'TEMPLATE_IDX': 2},\n",
       "  {'[PLACE]': 'office',\n",
       "   '[OBJECT]': 'snack',\n",
       "   'text': 'Then, Jack and Laura were thinking about going to the office. Jack wanted to give a snack to Laura',\n",
       "   'IO': 'Laura',\n",
       "   'S': 'Jack',\n",
       "   'TEMPLATE_IDX': 6},\n",
       "  {'[PLACE]': 'store',\n",
       "   '[OBJECT]': 'drink',\n",
       "   'text': 'When Luke and Paul got a drink at the store, Luke decided to give it to Paul',\n",
       "   'IO': 'Paul',\n",
       "   'S': 'Luke',\n",
       "   'TEMPLATE_IDX': 4},\n",
       "  {'[PLACE]': 'restaurant',\n",
       "   '[OBJECT]': 'basketball',\n",
       "   'text': 'Then, Tyler and Russell were working at the restaurant. Russell decided to give a basketball to Tyler',\n",
       "   'IO': 'Tyler',\n",
       "   'S': 'Russell',\n",
       "   'TEMPLATE_IDX': 12},\n",
       "  {'[PLACE]': 'school',\n",
       "   '[OBJECT]': 'drink',\n",
       "   'text': 'Then, Kate and Andre were thinking about going to the school. Kate wanted to give a drink to Andre',\n",
       "   'IO': 'Andre',\n",
       "   'S': 'Kate',\n",
       "   'TEMPLATE_IDX': 6},\n",
       "  {'[PLACE]': 'office',\n",
       "   '[OBJECT]': 'ring',\n",
       "   'text': 'Then, Thomas and Jacob had a lot of fun at the office. Jacob gave a ring to Thomas',\n",
       "   'IO': 'Thomas',\n",
       "   'S': 'Jacob',\n",
       "   'TEMPLATE_IDX': 7},\n",
       "  {'[PLACE]': 'office',\n",
       "   '[OBJECT]': 'snack',\n",
       "   'text': 'Then, Louis and Max went to the office. Max gave a snack to Louis',\n",
       "   'IO': 'Louis',\n",
       "   'S': 'Max',\n",
       "   'TEMPLATE_IDX': 8},\n",
       "  {'[PLACE]': 'restaurant',\n",
       "   '[OBJECT]': 'bone',\n",
       "   'text': 'Then, Alex and Sullivan had a long argument, and afterwards Sullivan said to Alex',\n",
       "   'IO': 'Alex',\n",
       "   'S': 'Sullivan',\n",
       "   'TEMPLATE_IDX': 9},\n",
       "  {'[PLACE]': 'hospital',\n",
       "   '[OBJECT]': 'ring',\n",
       "   'text': 'Then, Sullivan and Anthony were working at the hospital. Sullivan decided to give a ring to Anthony',\n",
       "   'IO': 'Anthony',\n",
       "   'S': 'Sullivan',\n",
       "   'TEMPLATE_IDX': 13},\n",
       "  {'[PLACE]': 'store',\n",
       "   '[OBJECT]': 'snack',\n",
       "   'text': 'Then, Andy and Prince were working at the store. Andy decided to give a snack to Prince',\n",
       "   'IO': 'Prince',\n",
       "   'S': 'Andy',\n",
       "   'TEMPLATE_IDX': 13}],\n",
       " 'groups': [array([0, 2, 6]),\n",
       "  array([15]),\n",
       "  array([5]),\n",
       "  array([ 1, 14, 17]),\n",
       "  array([13]),\n",
       "  array([16, 19]),\n",
       "  array([10, 12, 20]),\n",
       "  array([ 8, 21]),\n",
       "  array([ 9, 22]),\n",
       "  array([ 3,  7, 11]),\n",
       "  array([ 4, 18]),\n",
       "  array([23, 24])],\n",
       " 'sentences': ['When Victoria and Jane got a snack at the store, Jane decided to give it to Victoria',\n",
       "  'When Sullivan and Rose got a necklace at the garden, Sullivan decided to give it to Rose',\n",
       "  'When Alan and Alex got a drink at the store, Alex decided to give it to Alan',\n",
       "  'Then, Jessica and Crystal had a long argument, and afterwards Jessica said to Crystal',\n",
       "  'Then, Jonathan and Kevin were working at the school. Kevin decided to give a necklace to Jonathan',\n",
       "  'After Prince and Daniel went to the station, Daniel gave a computer to Prince',\n",
       "  'When Jeremy and Warren got a bone at the garden, Warren decided to give it to Jeremy',\n",
       "  'Then, Frank and Rose had a long argument, and afterwards Frank said to Rose',\n",
       "  'Then, Victoria and Peter went to the hospital. Peter gave a computer to Victoria',\n",
       "  'Then, Kevin and William had a long argument, and afterwards William said to Kevin',\n",
       "  'Then, Edward and Ryan had a lot of fun at the house. Ryan gave a drink to Edward',\n",
       "  'Then, Jake and Clark had a long argument, and afterwards Jake said to Clark',\n",
       "  'Then, Paul and Laura had a lot of fun at the restaurant. Laura gave a drink to Paul',\n",
       "  'After Ruby and Kelly went to the station, Ruby gave a ring to Kelly',\n",
       "  'When William and Robert got a bone at the house, William decided to give it to Robert',\n",
       "  'Then, David and Kyle went to the school. David gave a basketball to Kyle',\n",
       "  'Then, Jack and Laura were thinking about going to the office. Jack wanted to give a snack to Laura',\n",
       "  'When Luke and Paul got a drink at the store, Luke decided to give it to Paul',\n",
       "  'Then, Tyler and Russell were working at the restaurant. Russell decided to give a basketball to Tyler',\n",
       "  'Then, Kate and Andre were thinking about going to the school. Kate wanted to give a drink to Andre',\n",
       "  'Then, Thomas and Jacob had a lot of fun at the office. Jacob gave a ring to Thomas',\n",
       "  'Then, Louis and Max went to the office. Max gave a snack to Louis',\n",
       "  'Then, Alex and Sullivan had a long argument, and afterwards Sullivan said to Alex',\n",
       "  'Then, Sullivan and Anthony were working at the hospital. Sullivan decided to give a ring to Anthony',\n",
       "  'Then, Andy and Prince were working at the store. Andy decided to give a snack to Prince'],\n",
       " 'templates_by_prompt': ['ABBA',\n",
       "  'BABA',\n",
       "  'ABBA',\n",
       "  'BABA',\n",
       "  'ABBA',\n",
       "  'ABBA',\n",
       "  'ABBA',\n",
       "  'BABA',\n",
       "  'ABBA',\n",
       "  'ABBA',\n",
       "  'ABBA',\n",
       "  'BABA',\n",
       "  'ABBA',\n",
       "  'BABA',\n",
       "  'BABA',\n",
       "  'BABA',\n",
       "  'BABA',\n",
       "  'BABA',\n",
       "  'ABBA',\n",
       "  'BABA',\n",
       "  'ABBA',\n",
       "  'ABBA',\n",
       "  'ABBA',\n",
       "  'BABA',\n",
       "  'BABA'],\n",
       " 'toks': tensor([[ 2215, 12313,   290, 12091,  1392,   257, 26906,   379,   262,  3650,\n",
       "             11, 12091,  3066,   284,  1577,   340,   284, 12313, 50256, 50256,\n",
       "          50256],\n",
       "         [ 2215, 18501,   290,  8049,  1392,   257, 38987,   379,   262, 11376,\n",
       "             11, 18501,  3066,   284,  1577,   340,   284,  8049, 50256, 50256,\n",
       "          50256],\n",
       "         [ 2215, 12246,   290,  4422,  1392,   257,  4144,   379,   262,  3650,\n",
       "             11,  4422,  3066,   284,  1577,   340,   284, 12246, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11, 17352,   290, 12969,   550,   257,   890,  4578,    11,\n",
       "            290, 12979, 17352,   531,   284, 12969, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11, 11232,   290,  7939,   547,  1762,   379,   262,  1524,\n",
       "             13,  7939,  3066,   284,  1577,   257, 38987,   284, 11232, 50256,\n",
       "          50256],\n",
       "         [ 3260,  9005,   290,  7806,  1816,   284,   262,  4429,    11,  7806,\n",
       "           2921,   257,  3644,   284,  9005, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 2215, 11753,   290, 11328,  1392,   257,  9970,   379,   262, 11376,\n",
       "             11, 11328,  3066,   284,  1577,   340,   284, 11753, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11,  5278,   290,  8049,   550,   257,   890,  4578,    11,\n",
       "            290, 12979,  5278,   531,   284,  8049, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11, 12313,   290,  5613,  1816,   284,   262,  4436,    13,\n",
       "           5613,  2921,   257,  3644,   284, 12313, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11,  7939,   290,  3977,   550,   257,   890,  4578,    11,\n",
       "            290, 12979,  3977,   531,   284,  7939, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11, 10443,   290,  6047,   550,   257,  1256,   286,  1257,\n",
       "            379,   262,  2156,    13,  6047,  2921,   257,  4144,   284, 10443,\n",
       "          50256],\n",
       "         [ 6423,    11, 14757,   290, 11264,   550,   257,   890,  4578,    11,\n",
       "            290, 12979, 14757,   531,   284, 11264, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11,  3362,   290, 16753,   550,   257,  1256,   286,  1257,\n",
       "            379,   262,  7072,    13, 16753,  2921,   257,  4144,   284,  3362,\n",
       "          50256],\n",
       "         [ 3260, 10888,   290,  9077,  1816,   284,   262,  4429,    11, 10888,\n",
       "           2921,   257,  5858,   284,  9077, 50256, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 2215,  3977,   290,  5199,  1392,   257,  9970,   379,   262,  2156,\n",
       "             11,  3977,  3066,   284,  1577,   340,   284,  5199, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11,  3271,   290, 14316,  1816,   284,   262,  1524,    13,\n",
       "           3271,  2921,   257,  9669,   284, 14316, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11,  3619,   290, 16753,   547,  3612,   546,  1016,   284,\n",
       "            262,  2607,    13,  3619,  2227,   284,  1577,   257, 26906,   284,\n",
       "          16753],\n",
       "         [ 2215, 11336,   290,  3362,  1392,   257,  4144,   379,   262,  3650,\n",
       "             11, 11336,  3066,   284,  1577,   340,   284,  3362, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11, 14886,   290, 11563,   547,  1762,   379,   262,  7072,\n",
       "             13, 11563,  3066,   284,  1577,   257,  9669,   284, 14886, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11, 16693,   290, 10948,   547,  3612,   546,  1016,   284,\n",
       "            262,  1524,    13, 16693,  2227,   284,  1577,   257,  4144,   284,\n",
       "          10948],\n",
       "         [ 6423,    11,  5658,   290, 12806,   550,   257,  1256,   286,  1257,\n",
       "            379,   262,  2607,    13, 12806,  2921,   257,  5858,   284,  5658,\n",
       "          50256],\n",
       "         [ 6423,    11,  5593,   290,  5436,  1816,   284,   262,  2607,    13,\n",
       "           5436,  2921,   257, 26906,   284,  5593, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11,  4422,   290, 18501,   550,   257,   890,  4578,    11,\n",
       "            290, 12979, 18501,   531,   284,  4422, 50256, 50256, 50256, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11, 18501,   290,  9953,   547,  1762,   379,   262,  4436,\n",
       "             13, 18501,  3066,   284,  1577,   257,  5858,   284,  9953, 50256,\n",
       "          50256],\n",
       "         [ 6423,    11, 12382,   290,  9005,   547,  1762,   379,   262,  3650,\n",
       "             13, 12382,  3066,   284,  1577,   257, 26906,   284,  9005, 50256,\n",
       "          50256]], device='cuda:0'),\n",
       " 'word_idx': {'IO': tensor([1, 3, 1, 4, 2, 1, 1, 4, 2, 2, 2, 4, 2, 3, 3, 4, 4, 3, 2, 4, 2, 2, 2, 4,\n",
       "          4]),\n",
       "  'IO-1': tensor([0, 2, 0, 3, 1, 0, 0, 3, 1, 1, 1, 3, 1, 2, 2, 3, 3, 2, 1, 3, 1, 1, 1, 3,\n",
       "          3]),\n",
       "  'IO+1': tensor([2, 4, 2, 5, 3, 2, 2, 5, 3, 3, 3, 5, 3, 4, 4, 5, 5, 4, 3, 5, 3, 3, 3, 5,\n",
       "          5]),\n",
       "  'S1': tensor([3, 1, 3, 2, 4, 3, 3, 2, 4, 4, 4, 2, 4, 1, 1, 2, 2, 1, 4, 2, 4, 4, 4, 2,\n",
       "          2]),\n",
       "  'S1-1': tensor([2, 0, 2, 1, 3, 2, 2, 1, 3, 3, 3, 1, 3, 0, 0, 1, 1, 0, 3, 1, 3, 3, 3, 1,\n",
       "          1]),\n",
       "  'S1+1': tensor([4, 2, 4, 3, 5, 4, 4, 3, 5, 5, 5, 3, 5, 2, 2, 3, 3, 2, 5, 3, 5, 5, 5, 3,\n",
       "          3]),\n",
       "  'S2': tensor([11, 11, 11, 12, 11,  9, 11, 12, 10, 12, 14, 12, 14,  9, 11, 10, 13, 11,\n",
       "          11, 13, 14, 10, 12, 11, 11]),\n",
       "  'end': tensor([16, 16, 16, 14, 17, 13, 16, 14, 14, 14, 18, 14, 18, 13, 16, 14, 19, 16,\n",
       "          17, 19, 18, 14, 14, 17, 17]),\n",
       "  'starts': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0]),\n",
       "  'punct': tensor([10, 10, 10,  9, 10,  8, 10,  9,  9,  9, 13,  9, 13,  8, 10,  9, 12, 10,\n",
       "          10, 12, 13,  9,  9, 10, 10])},\n",
       " 'prepend_bos': False,\n",
       " 'N': 25,\n",
       " 'max_len': 21,\n",
       " 'io_tokenIDs': [12313,\n",
       "  8049,\n",
       "  12246,\n",
       "  12969,\n",
       "  11232,\n",
       "  9005,\n",
       "  11753,\n",
       "  8049,\n",
       "  12313,\n",
       "  7939,\n",
       "  10443,\n",
       "  11264,\n",
       "  3362,\n",
       "  9077,\n",
       "  5199,\n",
       "  14316,\n",
       "  16753,\n",
       "  3362,\n",
       "  14886,\n",
       "  10948,\n",
       "  5658,\n",
       "  5593,\n",
       "  4422,\n",
       "  9953,\n",
       "  9005],\n",
       " 's_tokenIDs': [12091,\n",
       "  18501,\n",
       "  4422,\n",
       "  17352,\n",
       "  7939,\n",
       "  7806,\n",
       "  11328,\n",
       "  5278,\n",
       "  5613,\n",
       "  3977,\n",
       "  6047,\n",
       "  14757,\n",
       "  16753,\n",
       "  10888,\n",
       "  3977,\n",
       "  3271,\n",
       "  3619,\n",
       "  11336,\n",
       "  11563,\n",
       "  16693,\n",
       "  12806,\n",
       "  5436,\n",
       "  18501,\n",
       "  18501,\n",
       "  12382],\n",
       " 'tokenized_prompts': ['When| Victoria| and| Jane| got| a| snack| at| the| store|,| Jane| decided| to| give| it| to| Victoria|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'When| Sullivan| and| Rose| got| a| necklace| at| the| garden|,| Sullivan| decided| to| give| it| to| Rose|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'When| Alan| and| Alex| got| a| drink| at| the| store|,| Alex| decided| to| give| it| to| Alan|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Jessica| and| Crystal| had| a| long| argument|,| and| afterwards| Jessica| said| to| Crystal|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Jonathan| and| Kevin| were| working| at| the| school|.| Kevin| decided| to| give| a| necklace| to| Jonathan|<|endoftext|>|<|endoftext|>',\n",
       "  'After| Prince| and| Daniel| went| to| the| station|,| Daniel| gave| a| computer| to| Prince|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'When| Jeremy| and| Warren| got| a| bone| at| the| garden|,| Warren| decided| to| give| it| to| Jeremy|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Frank| and| Rose| had| a| long| argument|,| and| afterwards| Frank| said| to| Rose|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Victoria| and| Peter| went| to| the| hospital|.| Peter| gave| a| computer| to| Victoria|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Kevin| and| William| had| a| long| argument|,| and| afterwards| William| said| to| Kevin|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Edward| and| Ryan| had| a| lot| of| fun| at| the| house|.| Ryan| gave| a| drink| to| Edward|<|endoftext|>',\n",
       "  'Then|,| Jake| and| Clark| had| a| long| argument|,| and| afterwards| Jake| said| to| Clark|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Paul| and| Laura| had| a| lot| of| fun| at| the| restaurant|.| Laura| gave| a| drink| to| Paul|<|endoftext|>',\n",
       "  'After| Ruby| and| Kelly| went| to| the| station|,| Ruby| gave| a| ring| to| Kelly|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'When| William| and| Robert| got| a| bone| at| the| house|,| William| decided| to| give| it| to| Robert|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| David| and| Kyle| went| to| the| school|.| David| gave| a| basketball| to| Kyle|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Jack| and| Laura| were| thinking| about| going| to| the| office|.| Jack| wanted| to| give| a| snack| to| Laura',\n",
       "  'When| Luke| and| Paul| got| a| drink| at| the| store|,| Luke| decided| to| give| it| to| Paul|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Tyler| and| Russell| were| working| at| the| restaurant|.| Russell| decided| to| give| a| basketball| to| Tyler|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Kate| and| Andre| were| thinking| about| going| to| the| school|.| Kate| wanted| to| give| a| drink| to| Andre',\n",
       "  'Then|,| Thomas| and| Jacob| had| a| lot| of| fun| at| the| office|.| Jacob| gave| a| ring| to| Thomas|<|endoftext|>',\n",
       "  'Then|,| Louis| and| Max| went| to| the| office|.| Max| gave| a| snack| to| Louis|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Alex| and| Sullivan| had| a| long| argument|,| and| afterwards| Sullivan| said| to| Alex|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Sullivan| and| Anthony| were| working| at| the| hospital|.| Sullivan| decided| to| give| a| ring| to| Anthony|<|endoftext|>|<|endoftext|>',\n",
       "  'Then|,| Andy| and| Prince| were| working| at| the| store|.| Andy| decided| to| give| a| snack| to| Prince|<|endoftext|>|<|endoftext|>'],\n",
       " 'device': device(type='cuda')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292dfbf6",
   "metadata": {},
   "source": [
    "# Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601a7d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      Sentences from IOI vs ABC distribution                                       </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> IOI prompt                              </span>┃<span style=\"font-weight: bold\"> IOI subj </span>┃<span style=\"font-weight: bold\"> IOI indirect obj </span>┃<span style=\"font-weight: bold\"> ABC prompt                              </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> got a snack at   │ Jane     │ Victoria         │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> got a snack at   │\n",
       "│ the store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> decided to give it to   │          │                  │ the store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jane</span> decided to give it to   │\n",
       "│ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span>                                │          │                  │ <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Victoria</span>                                │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span> got a necklace   │ Sullivan │ Rose             │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span> got a necklace   │\n",
       "│ at the garden, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> decided to give │          │                  │ at the garden, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Sullivan</span> decided to give │\n",
       "│ it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span>                              │          │                  │ it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Rose</span>                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> got a drink at the   │ Alex     │ Alan             │ When <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> got a drink at the   │\n",
       "│ store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> decided to give it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span>  │          │                  │ store, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alex</span> decided to give it to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Alan</span>  │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span> had a long    │ Jessica  │ Crystal          │ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span> had a long    │\n",
       "│ argument, and afterwards <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> said   │          │                  │ argument, and afterwards <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jessica</span> said   │\n",
       "│ to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span>                              │          │                  │ to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Crystal</span>                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> were working   │ Kevin    │ Jonathan         │ Then, <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span> and <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> were working   │\n",
       "│ at the school. <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> decided to give a  │          │                  │ at the school. <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Kevin</span> decided to give a  │\n",
       "│ necklace to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span>                    │          │                  │ necklace to <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold; text-decoration: underline\">Jonathan</span>                    │\n",
       "│                                         │          │                  │                                         │\n",
       "└─────────────────────────────────────────┴──────────┴──────────────────┴─────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                      Sentences from IOI vs ABC distribution                                       \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mIOI prompt                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIOI subj\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIOI indirect obj\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mABC prompt                             \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ When \u001b[1;4;38;5;208mVictoria\u001b[0m and \u001b[1;4;38;5;208mJane\u001b[0m got a snack at   │ Jane     │ Victoria         │ When \u001b[1;4;38;5;208mVictoria\u001b[0m and \u001b[1;4;38;5;208mJane\u001b[0m got a snack at   │\n",
       "│ the store, \u001b[1;4;38;5;208mJane\u001b[0m decided to give it to   │          │                  │ the store, \u001b[1;4;38;5;208mJane\u001b[0m decided to give it to   │\n",
       "│ \u001b[1;4;38;5;208mVictoria\u001b[0m                                │          │                  │ \u001b[1;4;38;5;208mVictoria\u001b[0m                                │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When \u001b[1;4;38;5;208mSullivan\u001b[0m and \u001b[1;4;38;5;208mRose\u001b[0m got a necklace   │ Sullivan │ Rose             │ When \u001b[1;4;38;5;208mSullivan\u001b[0m and \u001b[1;4;38;5;208mRose\u001b[0m got a necklace   │\n",
       "│ at the garden, \u001b[1;4;38;5;208mSullivan\u001b[0m decided to give │          │                  │ at the garden, \u001b[1;4;38;5;208mSullivan\u001b[0m decided to give │\n",
       "│ it to \u001b[1;4;38;5;208mRose\u001b[0m                              │          │                  │ it to \u001b[1;4;38;5;208mRose\u001b[0m                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ When \u001b[1;4;38;5;208mAlan\u001b[0m and \u001b[1;4;38;5;208mAlex\u001b[0m got a drink at the   │ Alex     │ Alan             │ When \u001b[1;4;38;5;208mAlan\u001b[0m and \u001b[1;4;38;5;208mAlex\u001b[0m got a drink at the   │\n",
       "│ store, \u001b[1;4;38;5;208mAlex\u001b[0m decided to give it to \u001b[1;4;38;5;208mAlan\u001b[0m  │          │                  │ store, \u001b[1;4;38;5;208mAlex\u001b[0m decided to give it to \u001b[1;4;38;5;208mAlan\u001b[0m  │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, \u001b[1;4;38;5;208mJessica\u001b[0m and \u001b[1;4;38;5;208mCrystal\u001b[0m had a long    │ Jessica  │ Crystal          │ Then, \u001b[1;4;38;5;208mJessica\u001b[0m and \u001b[1;4;38;5;208mCrystal\u001b[0m had a long    │\n",
       "│ argument, and afterwards \u001b[1;4;38;5;208mJessica\u001b[0m said   │          │                  │ argument, and afterwards \u001b[1;4;38;5;208mJessica\u001b[0m said   │\n",
       "│ to \u001b[1;4;38;5;208mCrystal\u001b[0m                              │          │                  │ to \u001b[1;4;38;5;208mCrystal\u001b[0m                              │\n",
       "│                                         │          │                  │                                         │\n",
       "│ Then, \u001b[1;4;38;5;208mJonathan\u001b[0m and \u001b[1;4;38;5;208mKevin\u001b[0m were working   │ Kevin    │ Jonathan         │ Then, \u001b[1;4;38;5;208mJonathan\u001b[0m and \u001b[1;4;38;5;208mKevin\u001b[0m were working   │\n",
       "│ at the school. \u001b[1;4;38;5;208mKevin\u001b[0m decided to give a  │          │                  │ at the school. \u001b[1;4;38;5;208mKevin\u001b[0m decided to give a  │\n",
       "│ necklace to \u001b[1;4;38;5;208mJonathan\u001b[0m                    │          │                  │ necklace to \u001b[1;4;38;5;208mJonathan\u001b[0m                    │\n",
       "│                                         │          │                  │                                         │\n",
       "└─────────────────────────────────────────┴──────────┴──────────────────┴─────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ioi_dataset import IOIDataset, format_prompt, make_table\n",
    "N = 25\n",
    "clean_dataset = IOIDataset(\n",
    "    prompt_type='mixed',\n",
    "    N=N,\n",
    "    tokenizer=model.tokenizer,\n",
    "    prepend_bos=False,\n",
    "    seed=1,\n",
    "    device=device\n",
    ")\n",
    "corr_dataset = clean_dataset.gen_flipped_prompts('ABC->XYZ, BAB->XYZ')\n",
    "\n",
    "make_table(\n",
    "  colnames = [\"IOI prompt\", \"IOI subj\", \"IOI indirect obj\", \"ABC prompt\"],\n",
    "  cols = [\n",
    "    map(format_prompt, clean_dataset.sentences),\n",
    "    model.to_string(clean_dataset.s_tokenIDs).split(),\n",
    "    model.to_string(clean_dataset.io_tokenIDs).split(),\n",
    "    map(format_prompt, clean_dataset.sentences),\n",
    "  ],\n",
    "  title = \"Sentences from IOI vs ABC distribution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657f126",
   "metadata": {},
   "source": [
    "# Metric Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e71a358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42380]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'op3_pos': 12,\n",
       " 'operator_word': None,\n",
       " 'operands_alt': 'eight six five',\n",
       " 'operands_base': 'eight six five',\n",
       " 'operator_pos': None,\n",
       " 'op2_pos': 10,\n",
       " 'op1_pos': 8,\n",
       " 'res_alt_tok': [42380],\n",
       " 'res_base_tok': [42380],\n",
       " 'res_string': None,\n",
       " 'res_base_string': 'nineteen',\n",
       " 'res_alt_string': 'nineteen',\n",
       " 'device': 'cpu',\n",
       " 'multitoken': False,\n",
       " 'is_llama': False,\n",
       " 'is_opt': False,\n",
       " 'representation': 'words',\n",
       " 'extended_templates': True,\n",
       " 'template_id': '-',\n",
       " 'n_vars': 2,\n",
       " 'base_string': 'eight + six + five =',\n",
       " 'alt_string': 'eight + six + five =',\n",
       " 'few_shots': 'five + four + two = eleven. ',\n",
       " 'few_shots_t2': ' ',\n",
       " 'equation': '({x}+{y}+{z})',\n",
       " 'enc': GPTNeoXTokenizerFast(name_or_path='EleutherAI/pythia-12b-deduped-v0', vocab_size=50254, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t1: AddedToken(\"<|padding|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t50254: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50255: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50256: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50257: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50258: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50259: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50260: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50261: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50262: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50263: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50264: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50265: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50266: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50267: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50268: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50269: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50270: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50271: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50272: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50273: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50274: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50275: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " \t50276: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       " },\n",
       " 'len_few_shots': 9,\n",
       " 'len_few_shots_t2': 1,\n",
       " 'base_string_tok_list': [12071,\n",
       "  559,\n",
       "  1740,\n",
       "  559,\n",
       "  767,\n",
       "  426,\n",
       "  19525,\n",
       "  15,\n",
       "  4314,\n",
       "  559,\n",
       "  2800,\n",
       "  559,\n",
       "  2620,\n",
       "  426],\n",
       " 'alt_string_tok_list': [209,\n",
       "  209,\n",
       "  209,\n",
       "  209,\n",
       "  209,\n",
       "  209,\n",
       "  209,\n",
       "  0,\n",
       "  4314,\n",
       "  559,\n",
       "  2800,\n",
       "  559,\n",
       "  2620,\n",
       "  426],\n",
       " 'base_string_tok': tensor([[12071,   559,  1740,   559,   767,   426, 19525,    15,  4314,   559,\n",
       "           2800,   559,  2620,   426]]),\n",
       " 'alt_string_tok': tensor([[ 209,  209,  209,  209,  209,  209,  209,    0, 4314,  559, 2800,  559,\n",
       "          2620,  426]]),\n",
       " 'pred_alt_string': ' thirteen',\n",
       " 'pred_res_alt_tok': [27291]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervention = intervention_list[0]\n",
    "print(intervention.res_base_tok)\n",
    "intervention.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d0ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.06]\n",
      "[12.125]\n"
     ]
    }
   ],
   "source": [
    "intervention = intervention_list[0]\n",
    "with torch.no_grad():\n",
    "    clean_logits = model(intervention.base_string_tok).cpu().numpy()\n",
    "    corrupt_logits = model(intervention.alt_string_tok).cpu().numpy()\n",
    "    clean_logit = clean_logits[:, -1, intervention.res_base_tok[0]]\n",
    "    corrupt_logit = corrupt_logits[:, -1, intervention.pred_res_alt_tok[0]]\n",
    "    logit_diff = corrupt_logit - clean_logit\n",
    "    print(clean_logit)\n",
    "    print(corrupt_logit)\n",
    "\n",
    "    \n",
    "    # clean_logit_argmax = torch.argmax(clean_logits, dim=2)\n",
    "    # corrupt_logit_argmax = torch.argmax(corrupt_logits, dim=2)\n",
    "    # print(clean_logit_argmax)\n",
    "    # next_word_index = clean_logit_argmax[0][-1]\n",
    "    # next_word = model.tokenizer.convert_ids_to_tokens(next_word_index.item())\n",
    "    # print(next_word)\n",
    "    \n",
    "    # clean_prediction = torch.argmax(clean_logits, dim=2)\n",
    "    # print(clean_prediction)\n",
    "    # next_word_index = clean_prediction[0][-1]\n",
    "    # next_word = tokenizer.convert_ids_to_tokens(next_word_index.item())\n",
    "    # print(next_word_index)\n",
    "    # print(next_word)\n",
    "    # print(torch.argmax(clean_logits[:, -1, :]))\n",
    "    # print(corrupt_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6edc4e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-12b-deduped-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "565c8a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ġthirteen'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(27291)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b9d4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean direction: 2.805162191390991, Corrupt direction: 1.4692586660385132\n",
      "Clean metric: 1.0, Corrupt metric: 0.0\n"
     ]
    }
   ],
   "source": [
    "def ave_logit_diff(\n",
    "    logits: Float[Tensor, 'batch seq d_vocab'],\n",
    "    ioi_dataset: IOIDataset,\n",
    "    per_prompt: bool = False\n",
    "):\n",
    "    '''\n",
    "        Return average logit difference between correct and incorrect answers\n",
    "    '''\n",
    "    # Get logits for indirect objects\n",
    "    batch_size = logits.size(0)\n",
    "    io_logits = logits[range(batch_size), ioi_dataset.word_idx['end'][:batch_size], ioi_dataset.io_tokenIDs[:batch_size]]\n",
    "    s_logits = logits[range(batch_size), ioi_dataset.word_idx['end'][:batch_size], ioi_dataset.s_tokenIDs[:batch_size]]\n",
    "    # Get logits for subject\n",
    "    logit_diff = io_logits - s_logits\n",
    "    return logit_diff if per_prompt else logit_diff.mean()\n",
    "\n",
    "with t.no_grad():\n",
    "    clean_logits = model(clean_dataset.toks)\n",
    "    corrupt_logits = model(corr_dataset.toks)\n",
    "    clean_logit_diff = ave_logit_diff(clean_logits, clean_dataset).item()\n",
    "    corrupt_logit_diff = ave_logit_diff(corrupt_logits, corr_dataset).item()\n",
    "\n",
    "def ioi_metric(\n",
    "    logits: Float[Tensor, \"batch seq_len d_vocab\"],\n",
    "    corrupted_logit_diff: float = corrupt_logit_diff,\n",
    "    clean_logit_diff: float = clean_logit_diff,\n",
    "    ioi_dataset: IOIDataset = clean_dataset\n",
    " ):\n",
    "    patched_logit_diff = ave_logit_diff(logits, ioi_dataset)\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (clean_logit_diff - corrupted_logit_diff)\n",
    "\n",
    "def negative_ioi_metric(logits: Float[Tensor, \"batch seq_len d_vocab\"]):\n",
    "    return -ioi_metric(logits)\n",
    "    \n",
    "# Get clean and corrupt logit differences\n",
    "with t.no_grad():\n",
    "    clean_metric = ioi_metric(clean_logits, corrupt_logit_diff, clean_logit_diff, clean_dataset)\n",
    "    corrupt_metric = ioi_metric(corrupt_logits, corrupt_logit_diff, clean_logit_diff, corr_dataset)\n",
    "\n",
    "print(f'Clean direction: {clean_logit_diff}, Corrupt direction: {corrupt_logit_diff}')\n",
    "print(f'Clean metric: {clean_metric}, Corrupt metric: {corrupt_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81ab6e",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activations requires 0.0004 GB of memory per token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head.9.9 -> [-0.029] -> head.11.10.q\n",
      "head.10.7 -> [0.029] -> head.11.10.q\n",
      "head.5.5 -> [0.021] -> head.8.6.v\n",
      "head.9.9 -> [-0.019] -> head.10.7.q\n",
      "head.5.5 -> [-0.019] -> mlp.5\n",
      "mlp.0 -> [0.018] -> head.6.9.q\n",
      "mlp.0 -> [-0.015] -> mlp.4\n",
      "head.5.5 -> [-0.015] -> head.6.9.q\n",
      "mlp.0 -> [-0.014] -> head.11.10.k\n",
      "head.3.0 -> [-0.014] -> mlp.5\n"
     ]
    }
   ],
   "source": [
    "model.reset_hooks()\n",
    "\n",
    "graph = EAP(\n",
    "    model,\n",
    "    clean_dataset.toks,\n",
    "    corr_dataset.toks,\n",
    "    ioi_metric,\n",
    "    upstream_nodes=[\"mlp\", \"head\"],\n",
    "    downstream_nodes=[\"mlp\", \"head\"],\n",
    "    batch_size=25\n",
    ")\n",
    "\n",
    "top_edges = graph.top_edges(n=10, abs_scores=True)\n",
    "for from_edge, to_edge, score in top_edges:\n",
    "    print(f'{from_edge} -> [{round(score, 3)}] -> {to_edge}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5bb8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('head.9.9', 'head.11.10.q', -0.0291709266602993),\n",
       " ('head.10.7', 'head.11.10.q', 0.02903885766863823),\n",
       " ('head.5.5', 'head.8.6.v', 0.020961817353963852),\n",
       " ('head.9.9', 'head.10.7.q', -0.01940404810011387),\n",
       " ('head.5.5', 'mlp.5', -0.018816370517015457),\n",
       " ('mlp.0', 'head.6.9.q', 0.01845172606408596),\n",
       " ('mlp.0', 'mlp.4', -0.0152858542278409),\n",
       " ('head.5.5', 'head.6.9.q', -0.014597196131944656),\n",
       " ('mlp.0', 'head.11.10.k', -0.013949546962976456),\n",
       " ('head.3.0', 'mlp.5', -0.013543691486120224)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
